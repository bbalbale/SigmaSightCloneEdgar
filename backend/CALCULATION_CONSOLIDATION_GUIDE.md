# Calculation Module Consolidation - Migration Guide

**Status:** Phase 1.1 Complete âœ… | Created: 2025-10-20
**Objective:** Eliminate duplicate calculations and establish clean architecture

---

## ðŸ“Š Executive Summary

### Problem Statement
Multiple analytics engines under `backend/app/calculations` reimplemented the same market value, exposure, and return pipelines, leading to:
- **Conflicting numbers**: Sign conventions disagreed between modules
- **Wasted computation**: Ignored cached snapshots, always recalculated
- **Code duplication**: 4 independent return fetchers, 3 regression scaffolds
- **Maintenance burden**: Bug fixes required 3Ã— updates

### Solution Architecture
Consolidate to canonical implementations:
- **market_data.py** â†’ Single source of truth for position valuation
- **regression_utils.py** â†’ Shared OLS regression scaffolding âœ… **COMPLETE**
- **portfolio_exposure_service.py** â†’ Cached exposure retrieval
- **factors_ridge.py + market_beta.py + interest_rate_beta.py** â†’ New calculation engines
- **Deprecate:** factor_utils.py and factors.py (old 7-factor OLS)

---

## âœ… Phase 1.1: Regression Utils (COMPLETED)

### What Was Done

#### 1. Created `app/calculations/regression_utils.py`
**Purpose:** DRY up OLS regression logic across all beta calculators

**Functions Implemented:**
```python
def run_single_factor_regression(
    y: np.ndarray,
    x: np.ndarray,
    cap: Optional[float] = None,
    confidence: float = 0.10,
    return_diagnostics: bool = True
) -> Dict[str, Any]:
    """
    Standardized OLS wrapper with beta capping and significance testing.

    Returns:
        {
            'beta': float (capped if needed),
            'alpha': float,
            'r_squared': float,
            'std_error': float,
            'p_value': float,
            'is_significant': bool,
            'capped': bool,
            'observations': int
        }
    """
```

**Key Features:**
- âœ… Beta capping at configurable limits (e.g., Â±5.0)
- âœ… Configurable significance threshold (0.05 strict, 0.10 relaxed)
- âœ… Minimal vs full diagnostics mode
- âœ… Comprehensive error handling (NaN detection, length validation)
- âœ… RÂ² quality classification (excellent/good/fair/poor/very_poor)
- âœ… Significance classification (***/**/*//ns)

#### 2. Created Comprehensive Test Suite
**File:** `tests/test_regression_utils.py`

**Test Coverage:**
- âœ… Perfect linear relationships (RÂ² = 1.0)
- âœ… No relationships (RÂ² â‰ˆ 0)
- âœ… Negative betas
- âœ… Beta capping (positive and negative)
- âœ… Confidence level variations
- âœ… Edge cases (insufficient data, NaN values, mismatched arrays)
- âœ… Real market data scenarios
- âœ… RÂ² classification boundaries
- âœ… Significance threshold boundaries
- âœ… Integration tests

**Results:** 35/35 tests passing âœ…

#### 3. Dependencies Added
```bash
uv pip install yfinance yahooquery
```

### Benefits Achieved
âœ… Single source of truth for regression logic
âœ… Eliminates ~150 lines of duplicate code across 3 modules
âœ… Consistent beta capping (was inconsistent before)
âœ… Unified significance testing
âœ… 100% test coverage on core regression logic

---

## ðŸ”„ Phase 1.2: Portfolio Exposure Service (NEXT PRIORITY)

### Objective
Create a service that retrieves portfolio exposures from cached snapshots first, falling back to real-time calculation only when necessary.

### Files to Create

#### 1. `app/services/portfolio_exposure_service.py`

```python
"""
Portfolio Exposure Service - Cached Snapshot Retrieval
Eliminates duplicate exposure calculations by using PortfolioSnapshot cache
"""
from datetime import date, timedelta
from decimal import Decimal
from typing import Dict, Any, List
from uuid import UUID

from sqlalchemy import select, and_
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.snapshots import PortfolioSnapshot
from app.models.positions import Position, PositionType
from app.calculations.portfolio import calculate_portfolio_exposures
from app.core.logging import get_logger

logger = get_logger(__name__)

OPTIONS_MULTIPLIER = 100  # Standard options contract size


async def get_portfolio_exposures(
    db: AsyncSession,
    portfolio_id: UUID,
    calculation_date: date,
    max_staleness_days: int = 3
) -> Dict[str, Any]:
    """
    Get portfolio net and gross exposures from snapshot or calculate real-time.

    Priority:
    1. Use latest snapshot if recent (within max_staleness_days)
    2. Calculate real-time from positions using calculate_portfolio_exposures()

    Args:
        db: Database session
        portfolio_id: Portfolio UUID
        calculation_date: Date for calculation
        max_staleness_days: Maximum days snapshot can be old (default 3)

    Returns:
        Dict with:
            - net_exposure: float (signed sum of positions)
            - gross_exposure: float (sum of absolute values)
            - long_exposure: float (sum of long positions)
            - short_exposure: float (sum of short positions)
            - position_count: int
            - source: 'snapshot' or 'real_time'
            - snapshot_date: date (if from snapshot) or None

    Example:
        >>> exposures = await get_portfolio_exposures(db, portfolio_id, date.today())
        >>> net = exposures['net_exposure']  # e.g., $2.3M for hedged portfolio
        >>> gross = exposures['gross_exposure']  # e.g., $6.6M for hedged portfolio
    """
    # Try to get latest snapshot
    snapshot_stmt = (
        select(PortfolioSnapshot)
        .where(
            and_(
                PortfolioSnapshot.portfolio_id == portfolio_id,
                PortfolioSnapshot.snapshot_date <= calculation_date
            )
        )
        .order_by(PortfolioSnapshot.snapshot_date.desc())
        .limit(1)
    )

    snapshot_result = await db.execute(snapshot_stmt)
    latest_snapshot = snapshot_result.scalar_one_or_none()

    # Check if snapshot is recent enough
    if latest_snapshot:
        staleness = (calculation_date - latest_snapshot.snapshot_date).days
        if staleness <= max_staleness_days:
            logger.info(
                f"Using snapshot exposures from {latest_snapshot.snapshot_date} "
                f"({staleness} days old): net=${float(latest_snapshot.net_exposure):,.0f}, "
                f"gross=${float(latest_snapshot.gross_exposure):,.0f}"
            )
            return {
                'net_exposure': float(latest_snapshot.net_exposure),
                'gross_exposure': float(latest_snapshot.gross_exposure),
                'long_exposure': float(latest_snapshot.long_exposure),
                'short_exposure': float(latest_snapshot.short_exposure),
                'position_count': latest_snapshot.position_count,
                'source': 'snapshot',
                'snapshot_date': latest_snapshot.snapshot_date
            }
        else:
            logger.warning(
                f"Latest snapshot is {staleness} days old "
                f"(max: {max_staleness_days}), calculating real-time"
            )

    # Fallback: Calculate real-time from positions
    logger.info("No recent snapshot found, calculating exposures real-time")

    positions_stmt = select(Position).where(
        and_(
            Position.portfolio_id == portfolio_id,
            Position.exit_date.is_(None)
        )
    )
    positions_result = await db.execute(positions_stmt)
    positions = positions_result.scalars().all()

    if not positions:
        logger.warning(f"No positions found for portfolio {portfolio_id}")
        return {
            'net_exposure': 0.0,
            'gross_exposure': 0.0,
            'long_exposure': 0.0,
            'short_exposure': 0.0,
            'position_count': 0,
            'source': 'real_time',
            'snapshot_date': None
        }

    # Prepare position data for calculate_portfolio_exposures()
    position_data = await prepare_positions_for_aggregation(db, positions)

    # Call the authoritative calculation function from portfolio.py
    aggregations = calculate_portfolio_exposures(position_data)

    logger.info(
        f"Calculated exposures real-time: net=${float(aggregations['net_exposure']):,.0f}, "
        f"gross=${float(aggregations['gross_exposure']):,.0f}"
    )

    return {
        'net_exposure': float(aggregations['net_exposure']),
        'gross_exposure': float(aggregations['gross_exposure']),
        'long_exposure': float(aggregations['long_exposure']),
        'short_exposure': float(aggregations['short_exposure']),
        'position_count': len(positions),
        'source': 'real_time',
        'snapshot_date': None
    }


async def prepare_positions_for_aggregation(
    db: AsyncSession,
    positions: List[Position]
) -> List[Dict[str, Any]]:
    """
    Prepare positions for exposure calculation.

    Used as fallback when no snapshot available.
    Calculates signed market values using canonical position valuation.

    Args:
        db: Database session
        positions: List of Position objects

    Returns:
        List of dicts with exposure, market_value, position_type for each position
    """
    from app.calculations.market_data import get_position_value  # Will create in Phase 1.3

    position_data = []

    for pos in positions:
        try:
            # Use canonical market_data function (to be created in Phase 1.3)
            # For now, inline the calculation
            if pos.market_value is not None:
                signed_value = float(pos.market_value)
                exposure = signed_value
            elif pos.last_price is not None:
                quantity = float(pos.quantity)
                price = float(pos.last_price)

                # Apply options multiplier
                if pos.position_type.name in ['LC', 'LP', 'SC', 'SP']:
                    multiplier = OPTIONS_MULTIPLIER
                else:
                    multiplier = 1

                # Apply sign for short positions
                if pos.position_type.name in ['SHORT', 'SC', 'SP']:
                    sign = -1
                else:
                    sign = 1

                market_value = sign * quantity * price * multiplier
                exposure = market_value
            else:
                logger.warning(f"Position {pos.id} has no price data, skipping")
                continue

            position_data.append({
                'exposure': Decimal(str(exposure)),
                'market_value': Decimal(str(abs(exposure))),
                'position_type': pos.position_type.name
            })

        except Exception as e:
            logger.error(f"Error preparing position {pos.id}: {e}")
            continue

    return position_data
```

#### 2. `tests/test_portfolio_exposure_service.py`

```python
"""
Test suite for portfolio_exposure_service.py
Tests snapshot caching, fallback logic, and exposure calculations
"""
import pytest
from datetime import date, timedelta
from decimal import Decimal
from uuid import uuid4

from app.services.portfolio_exposure_service import (
    get_portfolio_exposures,
    prepare_positions_for_aggregation
)
from app.models.snapshots import PortfolioSnapshot
from app.models.positions import Position, PositionType


@pytest.mark.asyncio
class TestGetPortfolioExposures:
    """Test exposure retrieval with snapshot caching"""

    async def test_uses_recent_snapshot(self, db_session, sample_portfolio):
        """Should use snapshot if within staleness limit"""
        # Create a recent snapshot
        snapshot = PortfolioSnapshot(
            id=uuid4(),
            portfolio_id=sample_portfolio.id,
            snapshot_date=date.today(),
            net_exposure=Decimal('2500000.00'),
            gross_exposure=Decimal('6500000.00'),
            long_exposure=Decimal('4500000.00'),
            short_exposure=Decimal('2000000.00'),
            position_count=30
        )
        db_session.add(snapshot)
        await db_session.commit()

        # Call service
        result = await get_portfolio_exposures(
            db_session,
            sample_portfolio.id,
            date.today()
        )

        # Should use snapshot
        assert result['source'] == 'snapshot'
        assert result['net_exposure'] == 2500000.00
        assert result['gross_exposure'] == 6500000.00
        assert result['snapshot_date'] == date.today()

    async def test_ignores_stale_snapshot(self, db_session, sample_portfolio):
        """Should recalculate if snapshot too old"""
        # Create a stale snapshot (5 days old)
        old_date = date.today() - timedelta(days=5)
        snapshot = PortfolioSnapshot(
            id=uuid4(),
            portfolio_id=sample_portfolio.id,
            snapshot_date=old_date,
            net_exposure=Decimal('2500000.00'),
            gross_exposure=Decimal('6500000.00'),
            position_count=30
        )
        db_session.add(snapshot)
        await db_session.commit()

        # Call service with max_staleness_days=3
        result = await get_portfolio_exposures(
            db_session,
            sample_portfolio.id,
            date.today(),
            max_staleness_days=3
        )

        # Should calculate real-time
        assert result['source'] == 'real_time'
        assert result['snapshot_date'] is None

    async def test_calculates_when_no_snapshot(self, db_session, sample_portfolio):
        """Should calculate real-time when no snapshot exists"""
        result = await get_portfolio_exposures(
            db_session,
            sample_portfolio.id,
            date.today()
        )

        assert result['source'] == 'real_time'
        assert 'net_exposure' in result
        assert 'gross_exposure' in result

    async def test_signed_exposure_calculation(self, db_session, sample_portfolio):
        """Should calculate signed exposures correctly"""
        # Create test positions: 2 longs, 1 short
        positions = [
            Position(
                id=uuid4(),
                portfolio_id=sample_portfolio.id,
                symbol='AAPL',
                quantity=Decimal('100'),
                position_type=PositionType.LONG,
                last_price=Decimal('150.00'),
                market_value=Decimal('15000.00')  # Positive
            ),
            Position(
                id=uuid4(),
                portfolio_id=sample_portfolio.id,
                symbol='GOOGL',
                quantity=Decimal('50'),
                position_type=PositionType.LONG,
                last_price=Decimal('140.00'),
                market_value=Decimal('7000.00')  # Positive
            ),
            Position(
                id=uuid4(),
                portfolio_id=sample_portfolio.id,
                symbol='TSLA',
                quantity=Decimal('-100'),  # Short
                position_type=PositionType.SHORT,
                last_price=Decimal('200.00'),
                market_value=Decimal('-20000.00')  # Negative
            )
        ]

        for pos in positions:
            db_session.add(pos)
        await db_session.commit()

        result = await get_portfolio_exposures(
            db_session,
            sample_portfolio.id,
            date.today()
        )

        # Net = 15000 + 7000 - 20000 = 2000
        # Gross = |15000| + |7000| + |-20000| = 42000
        assert result['net_exposure'] == pytest.approx(2000.00, abs=1)
        assert result['gross_exposure'] == pytest.approx(42000.00, abs=1)

    async def test_options_multiplier_applied(self, db_session, sample_portfolio):
        """Should apply 100x multiplier for options"""
        position = Position(
            id=uuid4(),
            portfolio_id=sample_portfolio.id,
            symbol='SPY',
            quantity=Decimal('10'),  # 10 contracts
            position_type=PositionType.LC,  # Long Call
            last_price=Decimal('5.00'),  # $5 per contract
            market_value=Decimal('5000.00')  # 10 Ã— 5 Ã— 100
        )
        db_session.add(position)
        await db_session.commit()

        result = await get_portfolio_exposures(
            db_session,
            sample_portfolio.id,
            date.today()
        )

        # Should be 10 contracts Ã— $5 Ã— 100 multiplier = $5000
        assert result['gross_exposure'] == pytest.approx(5000.00, abs=1)


# Add more test classes for:
# - test_prepare_positions_for_aggregation()
# - test_empty_portfolio()
# - test_all_exited_positions()
```

### Testing Strategy

1. **Unit Tests** (write first):
   - Snapshot cache hit/miss logic
   - Staleness threshold enforcement
   - Signed exposure calculations
   - Options multiplier application
   - Empty portfolio handling

2. **Integration Tests**:
   - Compare snapshot vs real-time results
   - Verify consistency with portfolio.py calculations

3. **Performance Tests**:
   - Measure cache hit rate
   - Compare query counts (should reduce from ~7 to ~1 on cache hit)

### Migration Steps

1. âœ… Write test suite first (TDD approach)
2. âœ… Implement `portfolio_exposure_service.py` to pass tests
3. âœ… Run tests to validate
4. **Update callers** (Phase 2.2):
   - `stress_testing.py` lines 74-183 â†’ Use service
   - `market_risk.py` line 339 â†’ Use service (remove `recalculate=True`)

---

## ðŸ”§ Phase 1.3: Market Data Enhancements

### Objective
Add canonical wrapper functions to `market_data.py` for position valuation and return retrieval.

### Code to Add to `app/calculations/market_data.py`

```python
# Add after existing functions, before fetch_historical_prices()

def get_position_value(
    position: Position,
    signed: bool = True,
    recalculate: bool = False
) -> Decimal:
    """
    Canonical position market value retrieval.

    This is the SINGLE SOURCE OF TRUTH for position valuation.
    All other modules should call this function instead of implementing their own logic.

    Args:
        position: Position object
        signed: If True, negative for shorts; if False, absolute value
        recalculate: Force recalculation vs using position.market_value

    Returns:
        Signed or absolute market value as Decimal

    Examples:
        >>> # Long position
        >>> pos = Position(quantity=100, last_price=50.00, position_type=PositionType.LONG)
        >>> get_position_value(pos, signed=True)  # 5000.00
        >>> get_position_value(pos, signed=False)  # 5000.00

        >>> # Short position
        >>> pos = Position(quantity=-100, last_price=50.00, position_type=PositionType.SHORT)
        >>> get_position_value(pos, signed=True)  # -5000.00
        >>> get_position_value(pos, signed=False)  # 5000.00 (absolute)
    """
    # Use cached value if available and not recalculating
    if not recalculate and position.market_value is not None:
        value = Decimal(str(position.market_value))
    else:
        # Recalculate using canonical logic
        multiplier = Decimal('100') if is_options_position(position) else Decimal('1')
        price = position.last_price or position.entry_price

        if price is None:
            value = Decimal('0')
        else:
            # Signed value (negative for shorts)
            value = position.quantity * price * multiplier

    # Return signed or absolute value
    if signed:
        return value
    else:
        return abs(value)


async def get_returns(
    db: AsyncSession,
    symbols: List[str],
    start_date: date,
    end_date: date,
    align_dates: bool = True
) -> pd.DataFrame:
    """
    Fetch aligned returns DataFrame for multiple symbols.

    This is the CANONICAL return fetcher used by all regression modules.
    Replaces duplicate implementations in market_beta, interest_rate_beta, etc.

    Args:
        db: Database session
        symbols: List of symbols to fetch
        start_date: Start date for returns
        end_date: End date for returns
        align_dates: If True, drop dates where ANY symbol is missing

    Returns:
        DataFrame with dates as index, symbols as columns, containing daily returns

    Example:
        >>> df = await get_returns(db, ['SPY', 'AAPL'], start_date, end_date)
        >>> spy_returns = df['SPY']  # Series of SPY daily returns
    """
    # Fetch historical prices using existing function
    price_df = await fetch_historical_prices(
        db=db,
        symbols=symbols,
        start_date=start_date,
        end_date=end_date
    )

    if price_df.empty:
        logger.warning("No price data available for return calculations")
        return pd.DataFrame()

    # Optionally align dates (drop rows with ANY missing values)
    if align_dates:
        price_df = price_df.dropna()

        if price_df.empty:
            logger.warning("No overlapping dates found across all symbols")
            return pd.DataFrame()

    # Calculate daily returns
    # Using fill_method=None to avoid FutureWarning (Pandas 2.1+)
    returns_df = price_df.pct_change(fill_method=None).dropna()

    logger.info(f"Calculated returns for {len(symbols)} symbols over {len(returns_df)} days")

    return returns_df
```

### Tests to Write

Create `tests/test_market_data_enhancements.py`:

```python
"""
Test enhancements to market_data.py
Tests get_position_value() and get_returns()
"""
import pytest
from decimal import Decimal
from datetime import date, timedelta

from app.calculations.market_data import get_position_value, get_returns
from app.models.positions import Position, PositionType


class TestGetPositionValue:
    """Test canonical position valuation"""

    def test_long_stock_signed(self):
        """Long stock should have positive signed value"""
        pos = Position(
            quantity=Decimal('100'),
            last_price=Decimal('50.00'),
            position_type=PositionType.LONG
        )

        value = get_position_value(pos, signed=True)
        assert value == Decimal('5000.00')

    def test_short_stock_signed(self):
        """Short stock should have negative signed value"""
        pos = Position(
            quantity=Decimal('-100'),
            last_price=Decimal('50.00'),
            position_type=PositionType.SHORT
        )

        value = get_position_value(pos, signed=True)
        assert value == Decimal('-5000.00')

    def test_short_stock_absolute(self):
        """Absolute value should always be positive"""
        pos = Position(
            quantity=Decimal('-100'),
            last_price=Decimal('50.00'),
            position_type=PositionType.SHORT
        )

        value = get_position_value(pos, signed=False)
        assert value == Decimal('5000.00')  # Absolute, not negative

    def test_long_call_multiplier(self):
        """Long call should apply 100x multiplier"""
        pos = Position(
            quantity=Decimal('10'),  # 10 contracts
            last_price=Decimal('5.00'),
            position_type=PositionType.LC
        )

        value = get_position_value(pos, signed=True)
        assert value == Decimal('5000.00')  # 10 Ã— 5 Ã— 100

    def test_cached_value_used(self):
        """Should use cached market_value if available"""
        pos = Position(
            quantity=Decimal('100'),
            last_price=Decimal('50.00'),
            market_value=Decimal('5500.00'),  # Different from calculated
            position_type=PositionType.LONG
        )

        value = get_position_value(pos, signed=True, recalculate=False)
        assert value == Decimal('5500.00')  # Uses cached

    def test_recalculate_ignores_cache(self):
        """Should recalculate when recalculate=True"""
        pos = Position(
            quantity=Decimal('100'),
            last_price=Decimal('50.00'),
            market_value=Decimal('5500.00'),  # Different
            position_type=PositionType.LONG
        )

        value = get_position_value(pos, signed=True, recalculate=True)
        assert value == Decimal('5000.00')  # Recalculated


@pytest.mark.asyncio
class TestGetReturns:
    """Test canonical return fetcher"""

    async def test_single_symbol_returns(self, db_session):
        """Should calculate returns for single symbol"""
        # Assumes MarketDataCache has price data
        returns = await get_returns(
            db_session,
            ['SPY'],
            start_date=date.today() - timedelta(days=30),
            end_date=date.today()
        )

        assert 'SPY' in returns.columns
        assert len(returns) > 0

    async def test_multiple_symbols_aligned(self, db_session):
        """Should align multiple symbols to common dates"""
        returns = await get_returns(
            db_session,
            ['SPY', 'AAPL'],
            start_date=date.today() - timedelta(days=30),
            end_date=date.today(),
            align_dates=True
        )

        # Should have no NaN values when aligned
        assert returns.isnull().sum().sum() == 0

    async def test_unaligned_allows_nan(self, db_session):
        """Should allow NaN when align_dates=False"""
        returns = await get_returns(
            db_session,
            ['SPY', 'OBSCURE_SYMBOL'],
            start_date=date.today() - timedelta(days=30),
            end_date=date.today(),
            align_dates=False
        )

        # May have NaN values for obscure symbol
        # Just verify it doesn't crash
        assert returns is not None
```

---

## ðŸ”„ Phase 2: Refactor Position Valuation

### Objective
Update all callers to use canonical `market_data.get_position_value()`.

### Files to Update

#### 1. `app/calculations/factor_utils.py`

**Changes:**
```python
# ADD deprecation warning at top of file
"""
âš ï¸ PARTIAL DEPRECATION - Some functions moved to regression_utils.py

Migrated to regression_utils.py:
- classify_r_squared â†’ regression_utils.classify_r_squared
- classify_significance â†’ regression_utils.classify_significance

Still used (temporary):
- normalize_factor_name
- PortfolioContext, load_portfolio_context
- get_default_storage_results, get_default_data_quality

Redirected to market_data.py:
- get_position_market_value â†’ market_data.get_position_value(signed=False)
- get_position_signed_exposure â†’ market_data.get_position_value(signed=True)
- _is_options_position â†’ market_data.is_options_position (REMOVE duplicate)
"""

# REDIRECT old functions
def get_position_market_value(
    position,
    use_stored: bool = True,
    recalculate: bool = False
) -> Decimal:
    """
    âš ï¸ DEPRECATED: Use market_data.get_position_value(signed=False) instead

    This function redirects to the canonical implementation.
    Will be removed in v2.0.
    """
    import warnings
    warnings.warn(
        "get_position_market_value is deprecated. "
        "Use market_data.get_position_value(signed=False) instead.",
        DeprecationWarning,
        stacklevel=2
    )

    from app.calculations.market_data import get_position_value
    return get_position_value(position, signed=False, recalculate=recalculate)


def get_position_signed_exposure(position) -> Decimal:
    """
    âš ï¸ DEPRECATED: Use market_data.get_position_value(signed=True) instead

    This function redirects to the canonical implementation.
    Will be removed in v2.0.
    """
    import warnings
    warnings.warn(
        "get_position_signed_exposure is deprecated. "
        "Use market_data.get_position_value(signed=True) instead.",
        DeprecationWarning,
        stacklevel=2
    )

    from app.calculations.market_data import get_position_value
    return get_position_value(position, signed=True)


# REMOVE _is_options_position (duplicate of market_data.is_options_position)
# Delete lines 145-158
```

#### 2. `app/calculations/factors_ridge.py`

**Update imports (lines 30-38):**
```python
# OLD
from app.calculations.factor_utils import (
    classify_r_squared,  # âŒ Move to regression_utils
    get_default_storage_results,  # âœ… Keep for now
    get_default_data_quality,  # âœ… Keep for now
    normalize_factor_name,  # âœ… Keep for now
    PortfolioContext,  # âœ… Keep for now
    load_portfolio_context,  # âœ… Keep for now
    get_position_market_value,  # âŒ Use market_data
    get_position_signed_exposure,  # âŒ Use market_data
)

# NEW
from app.calculations.regression_utils import classify_r_squared  # âœ… New home
from app.calculations.market_data import get_position_value  # âœ… Canonical
from app.calculations.factor_utils import (
    get_default_storage_results,
    get_default_data_quality,
    normalize_factor_name,
    PortfolioContext,
    load_portfolio_context,
)
```

**Update function calls:**
```python
# Find all usages of:
# - get_position_market_value(pos) â†’ get_position_value(pos, signed=False)
# - get_position_signed_exposure(pos) â†’ get_position_value(pos, signed=True)
```

#### 3. `app/calculations/market_beta.py`

**Update line 401 (in calculate_portfolio_market_beta):**
```python
# OLD
from app.calculations.factor_utils import get_position_signed_exposure
signed_exposure = float(get_position_signed_exposure(position))

# NEW
from app.calculations.market_data import get_position_value
signed_exposure = float(get_position_value(position, signed=True))
```

#### 4. `app/calculations/interest_rate_beta.py`

**Similar to market_beta.py**, update any valuation calls.

#### 5. `app/calculations/stress_testing.py`

**Replace lines 74-183 with:**
```python
# OLD: Inline exposure calculation with manual multiplier logic

# NEW: Use portfolio_exposure_service
from app.services.portfolio_exposure_service import get_portfolio_exposures

exposures = await get_portfolio_exposures(
    db=db,
    portfolio_id=portfolio_id,
    calculation_date=calculation_date
)

portfolio_market_value = exposures['net_exposure']
```

---

## ðŸ”„ Phase 3: Refactor Return Retrieval

### Objective
Replace duplicate return fetchers with calls to `market_data.get_returns()`.

### Files to Update

#### 1. `app/calculations/market_beta.py`

**Replace `fetch_returns_for_beta()` (lines 29-76):**
```python
# OLD: Entire function reimplements price fetch + pct_change

# NEW: Thin wrapper calling market_data.get_returns()
async def fetch_returns_for_beta(
    db: AsyncSession,
    symbol: str,
    start_date: date,
    end_date: date
) -> pd.Series:
    """
    Fetch returns for beta calculation.

    Wrapper around market_data.get_returns() for backward compatibility.
    """
    from app.calculations.market_data import get_returns

    df = await get_returns(db, [symbol], start_date, end_date)

    if df.empty or symbol not in df.columns:
        logger.warning(f"No return data for {symbol}")
        return pd.Series(dtype=float)

    return df[symbol]
```

#### 2. `app/calculations/interest_rate_beta.py`

**Replace `fetch_tlt_returns()` (lines 35-84):**
```python
# OLD: Reimplements price fetch + pct_change for TLT

# NEW: Call market_data.get_returns()
async def fetch_tlt_returns(
    db: AsyncSession,
    start_date: date,
    end_date: date
) -> pd.Series:
    """
    Fetch TLT returns for interest rate beta calculation.

    Wrapper around market_data.get_returns() for backward compatibility.
    """
    from app.calculations.market_data import get_returns

    df = await get_returns(db, ['TLT'], start_date, end_date)

    if df.empty or 'TLT' not in df.columns:
        logger.warning("No TLT return data")
        return pd.Series(dtype=float)

    # Convert to percentage (multiply by 100)
    return df['TLT'] * 100
```

#### 3. `app/calculations/factors.py` (if still using it)

**Already uses `fetch_historical_prices`**, but update to use `get_returns` wrapper:
```python
# In fetch_factor_returns() around line 119
# OLD:
returns_df = price_df_aligned.pct_change(fill_method=None).dropna()

# NEW:
from app.calculations.market_data import get_returns
returns_df = await get_returns(db, symbols, start_date, end_date, align_dates=True)
```

---

## ðŸ”„ Phase 4: Refactor Regression Scaffolding

### Objective
Replace inline OLS blocks with calls to `regression_utils.run_single_factor_regression()`.

### Files to Update

#### 1. `app/calculations/market_beta.py`

**In `calculate_position_market_beta()` (lines 171-190):**
```python
# OLD:
X_with_const = sm.add_constant(X)
model = sm.OLS(y, X_with_const).fit()

# Extract results
beta = float(model.params[1])
alpha = float(model.params[0])
r_squared = float(model.rsquared)
std_error = float(model.bse[1])
p_value = float(model.pvalues[1])

# Cap beta
original_beta = beta
beta = max(-BETA_CAP_LIMIT, min(BETA_CAP_LIMIT, beta))
is_significant = p_value < 0.10

# NEW:
from app.calculations.regression_utils import run_single_factor_regression

reg_result = run_single_factor_regression(
    y=y,  # Position returns
    x=X,  # SPY returns
    cap=BETA_CAP_LIMIT,
    confidence=0.10,
    return_diagnostics=True
)

if not reg_result['success']:
    return {
        'position_id': position_id,
        'symbol': position.symbol,
        'success': False,
        'error': reg_result.get('error', 'Regression failed')
    }

beta = reg_result['beta']
alpha = reg_result['alpha']
r_squared = reg_result['r_squared']
std_error = reg_result['std_error']
p_value = reg_result['p_value']
is_significant = reg_result['is_significant']
```

#### 2. `app/calculations/interest_rate_beta.py`

**Similar refactor in `calculate_position_ir_beta()` (lines 190-220):**
```python
# Replace OLS block with:
from app.calculations.regression_utils import run_single_factor_regression

reg_result = run_single_factor_regression(
    y=y,  # Position returns
    x=X,  # TLT returns
    cap=BETA_CAP_LIMIT,
    confidence=0.10,
    return_diagnostics=True
)

# Extract results
ir_beta_tlt = reg_result['beta']
alpha = reg_result['alpha']
r_squared = reg_result['r_squared']
std_error = reg_result['std_error']
p_value = reg_result['p_value']
```

---

## ðŸ”„ Phase 5-7: Remaining Tasks

### Phase 5: Expand Portfolio Exposure Service Usage

**File: `app/calculations/market_risk.py`**

Update `calculate_portfolio_market_beta()` line 339:
```python
# OLD:
value = get_position_market_value(position, recalculate=True)  # Wasteful!

# NEW:
from app.services.portfolio_exposure_service import get_portfolio_exposures

exposures = await get_portfolio_exposures(db, portfolio_id, calculation_date)
portfolio_value = exposures['net_exposure']
```

### Phase 6: Update Batch Orchestrator

**File: `app/batch/batch_orchestrator_v2.py`**

1. Check if using old `factors.py` â†’ Switch to `factors_ridge.py`
2. Add `market_beta.py` calculation step (if not already there)
3. Use `portfolio_exposure_service` instead of recalculating

### Phase 7: Add Deprecation Warnings

**File: `app/calculations/factors.py`**

Add header:
```python
"""
âš ï¸ DEPRECATED MODULE - Use factors_ridge.py instead

Old 7-factor OLS model with multicollinearity issues.
Replaced by:
- factors_ridge.py (6 non-market factors, Ridge regression)
- market_beta.py (Market beta, simple OLS vs SPY)
- interest_rate_beta.py (IR beta, OLS vs TLT)

This module will be removed in v2.0.
"""
```

---

## ðŸ“‹ Testing Checklist

### Unit Tests
- [x] âœ… `test_regression_utils.py` (35 tests passing)
- [ ] `test_portfolio_exposure_service.py` (Phase 1.2)
- [ ] `test_market_data_enhancements.py` (Phase 1.3)
- [ ] Update `test_market_beta.py` (verify regression_utils integration)
- [ ] Update `test_interest_rate_beta.py` (verify regression_utils integration)

### Integration Tests
- [ ] Run batch processing on 3 demo portfolios
- [ ] Compare gross/net exposures across all modules
- [ ] Verify snapshot cache hit rates
- [ ] Validate beta calculations match previous results

### Performance Benchmarks
- [ ] Measure query count reduction (target: ~60% fewer queries)
- [ ] Time batch processing before/after
- [ ] Track cache hit rate for exposure service

---

## ðŸš¨ Rollback Procedures

### If Tests Fail

1. **Regression Utils Issues:**
   - Files to revert: `regression_utils.py`, `test_regression_utils.py`
   - Modules still work independently (no breaking changes yet)

2. **Exposure Service Issues:**
   - Revert `portfolio_exposure_service.py`
   - Modules fall back to inline calculations

3. **Migration Issues:**
   - Each phase is independent
   - Can rollback individual files without affecting others
   - Git commits should be per-phase for easy rollback

### Emergency Contacts

If major issues arise:
- Check `CLAUDE.md` for diagnostic commands
- Review `TODO3.md` for known issues
- Consult `backend/STRESS_TEST_DIAGNOSIS_2025-10-20.md` for stress test specifics

---

## ðŸ“Š Success Metrics

### Code Quality
- âœ… Test coverage >80% on new modules
- âœ… Zero deprecation warnings in new code
- âœ… All type hints present
- âœ… Docstrings follow Google style

### Performance
- Target: 50-60% reduction in database queries for analytics
- Target: Cache hit rate >70% for exposure service
- No regression in batch processing time

### Correctness
- âœ… Gross/net exposures consistent across all modules
- âœ… Beta calculations match previous results (Â±0.001)
- âœ… All 3 demo portfolios process successfully

---

## ðŸŽ¯ Current Status

### âœ… Completed
- **Phase 1.1:** regression_utils.py (147 lines, 35 tests passing)

### ðŸ”„ In Progress
- **Phase 1.2:** portfolio_exposure_service.py (next priority)

### ðŸ“‹ Remaining
- Phases 1.3 through 7 (detailed above)
- Integration testing
- Documentation updates

---

## ðŸ“š Additional Resources

### Key Files
- `backend/CLAUDE.md` - Development guidelines
- `backend/TODO3.md` - Current work tracker
- `backend/_docs/reference/API_REFERENCE_V1.4.6.md` - API documentation

### Diagnostic Commands
```bash
# Test regression utils
cd backend && python -m pytest tests/test_regression_utils.py -v

# Test all calculations
cd backend && python -m pytest tests/test_*.py -k "calculation" -v

# Run batch processing
cd backend && uv run python scripts/test_batch_with_reports.py
```

---

**Last Updated:** 2025-10-20
**Maintained By:** SigmaSight Development Team
**Status:** Phase 1.1 Complete âœ…
