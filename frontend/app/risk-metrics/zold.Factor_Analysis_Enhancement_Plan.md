# Factor Analysis Enhancement Plan
**SigmaSight Backend - Calculation Engine Optimization**

**Version**: 1.0
**Date**: 2025-01-14
**Status**: Planning Phase
**Target Module**: `backend/app/calculations/factors.py`

---

## Executive Summary

### Current State Assessment

**Overall Rating: A- (9.0/10) - Excellent**

The current factor analysis implementation demonstrates institutional-quality methodology with several sophisticated design choices that exceed typical implementations:

**Key Strengths**:
- ‚úÖ Multivariate OLS regression (not sequential univariate)
- ‚úÖ Equity-based portfolio weighting (superior to notional weighting)
- ‚úÖ Proper leverage handling (weights sum to leverage ratio)
- ‚úÖ Comprehensive statistical outputs (R¬≤, p-values, standard errors)
- ‚úÖ Signed vs magnitude exposure distinction
- ‚úÖ Position-level dollar attribution
- ‚úÖ Graceful degradation with quality flags

**Current Limitations**:
- ‚ö†Ô∏è Duplicate database queries (~7 queries per calculation)
- ‚ö†Ô∏è No multicollinearity diagnostics (VIF, condition number)
- ‚ö†Ô∏è Statistical significance not used for quality assessment
- ‚ö†Ô∏è Factor name mapping duplicated across functions
- ‚ö†Ô∏è Inconsistent market value calculation approaches

### Enhancement Objectives

This plan proposes improvements in two categories:

1. **Code Efficiency & Architecture** (Performance + Maintainability)
   - Reduce database queries by ~62% (7 ‚Üí 3 queries)
   - Eliminate code duplication
   - Standardize data structures
   - Improve testability

2. **Statistical Enhancements** (Quality + Diagnostics)
   - Add multicollinearity detection
   - Implement significance thresholds
   - Classify model fit quality
   - Analyze factor correlations

**Target Rating: A+ (9.5/10)**

---

## Part I: Code Efficiency Improvements

### 1.1 Centralized Factor Name Normalization

**Current Problem** (Lines 671-679, 774-782):
```python
# Duplicated in store_position_factor_exposures
factor_name_mapping = {
    'Market': 'Market Beta',
    'Value': 'Value',
    # ... 7 factors
}

# EXACT DUPLICATE in aggregate_portfolio_factor_exposures
factor_name_mapping = {
    'Market': 'Market Beta',  # Same mapping!
    'Value': 'Value',
    # ... 7 factors
}
```

**Issues**:
- ‚ùå Violates DRY principle
- ‚ùå Must update in 2+ places if factor names change
- ‚ùå Risk of inconsistency

**Proposed Solution**:

Create new file: `backend/app/calculations/factor_utils.py`

```python
"""
Shared utilities for factor analysis calculations
"""
from typing import Dict, List
from uuid import UUID
from decimal import Decimal

# Centralized factor name mapping
FACTOR_NAME_MAPPING = {
    'Market': 'Market Beta',
    'Value': 'Value',
    'Growth': 'Growth',
    'Momentum': 'Momentum',
    'Quality': 'Quality',
    'Size': 'Size',
    'Low Volatility': 'Low Volatility'
}

def normalize_factor_name(calc_name: str) -> str:
    """
    Normalize calculation factor name to database factor name

    Args:
        calc_name: Factor name from regression (e.g., 'Market')

    Returns:
        Database factor name (e.g., 'Market Beta')
    """
    return FACTOR_NAME_MAPPING.get(calc_name, calc_name)

def get_inverse_factor_mapping() -> Dict[str, str]:
    """Get database name -> calculation name mapping"""
    return {v: k for k, v in FACTOR_NAME_MAPPING.items()}
```

**Impact**:
- ‚úÖ Single source of truth
- ‚úÖ Easy to extend with new factors
- ‚úÖ Consistent across all functions

**Priority**: üü¢ High Value, Low Risk
**Effort**: 30 minutes

---

### 1.2 Portfolio Context Object (Eliminate Duplicate DB Queries)

**Current Problem**:

The code queries the database **7+ times** in a single calculation:

1. **calculate_position_returns()** (line 132): Get active positions
2. **calculate_factor_betas_hybrid()** (line 458): Get positions for exposures
3. **_aggregate_portfolio_betas()** (line 557): Get portfolio for equity
4. **_aggregate_portfolio_betas()** (line 574): Get positions for weighting
5. **aggregate_portfolio_factor_exposures()** (line 791): Get positions again
6. **aggregate_portfolio_factor_exposures()** (line 815): Get portfolio again
7. **store_position_factor_exposures()** (line 664): Get factor definitions
8. **aggregate_portfolio_factor_exposures()** (line 767): Get factor definitions again

**Performance Impact**:
- Current: ~7-8 database round-trips
- Optimized: ~3 database round-trips
- **Improvement: 62% reduction in DB queries**

**Proposed Solution**:

Add to `backend/app/calculations/factor_utils.py`:

```python
from dataclasses import dataclass
from datetime import date
from typing import List, Dict, Optional
from uuid import UUID
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_, or_

from app.models.users import Portfolio
from app.models.positions import Position
from app.models.market_data import FactorDefinition

@dataclass
class PortfolioContext:
    """
    Pre-loaded portfolio context to avoid duplicate database queries.

    This object caches all necessary data for factor calculations,
    reducing database round-trips from ~7 to ~3 per calculation.
    """
    portfolio_id: UUID
    portfolio: Portfolio
    positions: List[Position]
    factor_definitions: List[FactorDefinition]
    factor_name_to_id: Dict[str, UUID]
    calculation_date: date

    # Cached properties
    _active_positions: Optional[List[Position]] = None
    _public_positions: Optional[List[Position]] = None

    @property
    def equity_balance(self) -> Decimal:
        """Portfolio equity balance for weighting calculations"""
        return self.portfolio.equity_balance

    @property
    def active_positions(self) -> List[Position]:
        """All active positions (excluding exited)"""
        if self._active_positions is None:
            self._active_positions = [
                p for p in self.positions
                if p.exit_date is None
            ]
        return self._active_positions

    @property
    def public_positions(self) -> List[Position]:
        """
        Active positions excluding PRIVATE investment class.
        These are the positions used for factor analysis.
        """
        if self._public_positions is None:
            self._public_positions = [
                p for p in self.active_positions
                if p.investment_class != 'PRIVATE' or p.investment_class is None
            ]
        return self._public_positions

    def get_position_count_summary(self) -> Dict[str, int]:
        """Get position counts for logging/diagnostics"""
        return {
            'total': len(self.positions),
            'active': len(self.active_positions),
            'public': len(self.public_positions),
            'private': len([p for p in self.active_positions
                           if p.investment_class == 'PRIVATE']),
            'exited': len([p for p in self.positions
                          if p.exit_date is not None])
        }


async def load_portfolio_context(
    db: AsyncSession,
    portfolio_id: UUID,
    calculation_date: date
) -> PortfolioContext:
    """
    Load all portfolio data needed for factor calculations in one batch.

    This function performs 3 database queries:
    1. Portfolio (for equity_balance)
    2. All positions (active and inactive)
    3. Factor definitions

    Args:
        db: Database session
        portfolio_id: Portfolio to load
        calculation_date: Date of calculation (for logging)

    Returns:
        PortfolioContext with all pre-loaded data

    Raises:
        ValueError: If portfolio not found or equity_balance invalid
    """
    from app.core.logging import get_logger
    logger = get_logger(__name__)

    # Query 1: Load portfolio
    portfolio_stmt = select(Portfolio).where(Portfolio.id == portfolio_id)
    portfolio_result = await db.execute(portfolio_stmt)
    portfolio = portfolio_result.scalar_one_or_none()

    if portfolio is None:
        raise ValueError(f"Portfolio {portfolio_id} not found")

    # Validate equity_balance
    if not portfolio.equity_balance or portfolio.equity_balance <= 0:
        raise ValueError(
            f"Portfolio {portfolio_id} has invalid equity_balance: {portfolio.equity_balance}. "
            "Equity-based factor calculation requires valid equity_balance."
        )

    # Query 2: Load all positions (we'll filter in properties)
    positions_stmt = select(Position).where(
        Position.portfolio_id == portfolio_id
    )
    positions_result = await db.execute(positions_stmt)
    positions = list(positions_result.scalars().all())

    # Query 3: Load factor definitions
    factor_stmt = select(FactorDefinition).where(
        FactorDefinition.is_active == True
    )
    factor_result = await db.execute(factor_stmt)
    factor_definitions = list(factor_result.scalars().all())

    # Build factor name mapping
    factor_name_to_id = {fd.name: fd.id for fd in factor_definitions}

    # Create context
    context = PortfolioContext(
        portfolio_id=portfolio_id,
        portfolio=portfolio,
        positions=positions,
        factor_definitions=factor_definitions,
        factor_name_to_id=factor_name_to_id,
        calculation_date=calculation_date
    )

    # Log summary
    counts = context.get_position_count_summary()
    logger.info(
        f"Loaded portfolio context: {counts['active']} active positions "
        f"({counts['public']} public, {counts['private']} private), "
        f"equity=${float(context.equity_balance):,.2f}"
    )

    return context
```

**Refactored Function Signatures**:

```python
async def calculate_position_returns(
    db: AsyncSession,
    portfolio_id: UUID,
    start_date: date,
    end_date: date,
    use_delta_adjusted: bool = False,
    context: Optional[PortfolioContext] = None  # NEW
) -> pd.DataFrame:
    """
    Calculate exposure-based daily returns for portfolio positions

    Args:
        context: Pre-loaded portfolio context (optional).
                If None, will load from database.
    """
    # Load context if not provided
    if context is None:
        context = await load_portfolio_context(db, portfolio_id, end_date)

    # Use context.public_positions instead of querying DB
    positions = context.public_positions

    if not positions:
        logger.warning(
            f"No public positions found. Summary: {context.get_position_count_summary()}"
        )
        return pd.DataFrame()

    # ... rest of function uses 'positions' variable
```

**Impact**:
- ‚úÖ 62% fewer database queries
- ‚úÖ Faster execution time
- ‚úÖ Better for batch processing
- ‚úÖ Easier to test (mock context object)

**Priority**: üî¥ Very High Value, Medium Risk
**Effort**: 4-5 hours (includes testing)

---

### 1.3 Shared Market Value Utilities

**Current Problem**:

Market value calculated differently in different places:

```python
# In _aggregate_portfolio_betas (lines 591-593)
multiplier = OPTIONS_MULTIPLIER if _is_options_position(position) else 1
market_value = abs(position.quantity * (position.last_price or position.entry_price) * multiplier)

# In aggregate_portfolio_factor_exposures (line 804)
market_val = float(position.market_value) if position.market_value else 0
```

These are **different approaches** - one calculates, one uses stored value. Could lead to inconsistencies.

**Proposed Solution**:

Add to `backend/app/calculations/factor_utils.py`:

```python
from app.constants.factors import OPTIONS_MULTIPLIER

def _is_options_position(position: Position) -> bool:
    """Check if position is an options position"""
    from app.models.positions import PositionType
    return position.position_type in [
        PositionType.LC, PositionType.LP, PositionType.SC, PositionType.SP
    ]

def get_position_market_value(
    position: Position,
    use_stored: bool = True,
    recalculate: bool = False
) -> Decimal:
    """
    Get position market value with consistent logic.

    Args:
        position: Position object
        use_stored: If True and position.market_value exists, use it.
        recalculate: If True, always recalculate (ignores use_stored)

    Returns:
        Market value as Decimal

    Note:
        Recalculated value = |quantity √ó price √ó multiplier|
        where multiplier = 100 for options, 1 for others
    """
    if not recalculate and use_stored and position.market_value:
        return Decimal(str(position.market_value))

    # Recalculate
    multiplier = OPTIONS_MULTIPLIER if _is_options_position(position) else 1
    price = position.last_price or position.entry_price

    if price is None:
        return Decimal('0')

    return abs(Decimal(str(position.quantity)) * Decimal(str(price)) * multiplier)

def get_position_signed_exposure(position: Position) -> Decimal:
    """
    Get signed exposure (negative for shorts, positive for longs).

    This is used for portfolio aggregation where direction matters.

    Returns:
        Positive for LONG/LC/LP, negative for SHORT/SC/SP
    """
    from app.models.positions import PositionType

    market_value = get_position_market_value(position)

    # Apply sign based on position type
    if position.position_type in [PositionType.SHORT, PositionType.SC, PositionType.SP]:
        return -market_value
    return market_value

def get_position_magnitude_exposure(position: Position) -> Decimal:
    """
    Get absolute magnitude exposure (always positive).

    This is used for gross exposure calculations.
    """
    return abs(get_position_market_value(position))
```

**Impact**:
- ‚úÖ Single source of truth for market value
- ‚úÖ Consistent calculations across functions
- ‚úÖ Clear signed vs magnitude distinction
- ‚úÖ Easy to update calculation logic

**Priority**: üü¢ High Value, Medium Risk
**Effort**: 1 hour

---

### 1.4 Consistent Storage Result Structures

**Current Problem**:

Skip payload structure (lines 301-304) might differ from success payload structure.

**Proposed Solution**:

Add to `backend/app/calculations/factor_utils.py`:

```python
def get_default_storage_results() -> Dict[str, Any]:
    """
    Get default storage results structure with consistent schema.

    This ensures skip and success cases have identical structure
    for easier API consumption and testing.
    """
    return {
        'position_storage': {
            'records_stored': 0,
            'positions_processed': 0,
            'errors': [],
            'skipped': False,
            'skip_reason': None
        },
        'portfolio_storage': {
            'records_stored': 0,
            'factors_processed': 0,
            'errors': [],
            'skipped': False,
            'skip_reason': None
        }
    }

def get_default_data_quality() -> Dict[str, Any]:
    """
    Get default data quality structure.

    Returns comprehensive quality metadata including:
    - Quality flag (FULL_HISTORY, LIMITED_HISTORY, etc.)
    - Position counts and classifications
    - Data availability metrics
    - Skip reasons and diagnostics
    """
    return {
        'quality_flag': None,
        'message': '',
        'positions_analyzed': 0,
        'positions_total': 0,
        'positions_private': 0,
        'positions_exited': 0,
        'data_days': 0,
        'regression_days': 0,
        'required_days': 0,
        'skip_reason': None,
        'calculation_attempted': True,
        'portfolio_equity': 0.0
    }
```

**Usage in calculate_factor_betas_hybrid**:

```python
async def calculate_factor_betas_hybrid(
    db: AsyncSession,
    portfolio_id: UUID,
    calculation_date: date,
    use_delta_adjusted: bool = False,
    context: Optional[PortfolioContext] = None
) -> Dict[str, Any]:
    # Initialize with defaults
    results = {
        'factor_betas': {},
        'position_betas': {},
        'data_quality': get_default_data_quality(),
        'metadata': {},
        'regression_stats': {},
        'storage_results': get_default_storage_results()
    }

    # Load context
    if context is None:
        context = await load_portfolio_context(db, portfolio_id, calculation_date)

    # Enhanced skip payload with full context
    if not context.public_positions:
        counts = context.get_position_count_summary()
        results['data_quality'].update({
            'flag': QUALITY_FLAG_NO_PUBLIC_POSITIONS,
            'quality_flag': QUALITY_FLAG_NO_PUBLIC_POSITIONS,
            'message': 'Portfolio contains no public positions with sufficient price history',
            'positions_total': counts['total'],
            'positions_private': counts['private'],
            'positions_exited': counts['exited'],
            'skip_reason': 'NO_PUBLIC_POSITIONS',
            'portfolio_equity': float(context.equity_balance)
        })
        results['storage_results']['position_storage']['skipped'] = True
        results['storage_results']['position_storage']['skip_reason'] = 'NO_PUBLIC_POSITIONS'
        results['storage_results']['portfolio_storage']['skipped'] = True
        results['storage_results']['portfolio_storage']['skip_reason'] = 'NO_PUBLIC_POSITIONS'
        results['metadata'] = {
            'calculation_date': calculation_date.isoformat(),
            'status': 'SKIPPED_NO_PUBLIC_POSITIONS',
            'portfolio_id': str(portfolio_id)
        }
        return results

    # ... rest of calculation
```

**Impact**:
- ‚úÖ Consistent API response structure
- ‚úÖ No KeyError from missing fields
- ‚úÖ Easier to consume in frontend
- ‚úÖ Better debugging information

**Priority**: üü¢ High Value, Low Risk
**Effort**: 45 minutes

---

## Part II: Statistical Enhancements

### 2.1 Multicollinearity Diagnostics

**Background**:

When factors are highly correlated, regression beta estimates become:
- Unstable (small data changes ‚Üí large beta changes)
- Unreliable (inflated standard errors)
- Difficult to interpret

**Academic Standards**:
- VIF > 10: Severe multicollinearity (requires action)
- VIF > 5: Moderate multicollinearity (investigate)
- Condition number > 100: Multicollinearity present

**Proposed Solution**:

Add to `backend/app/calculations/factor_utils.py`:

```python
import numpy as np
import pandas as pd
from typing import Dict, Any, List

def check_multicollinearity(X: pd.DataFrame) -> Dict[str, Any]:
    """
    Check for multicollinearity in factor matrix using VIF and condition number.

    Args:
        X: Factor returns matrix (n observations √ó k factors)

    Returns:
        Dictionary containing:
        - vif_values: Dict[factor_name, vif]
        - condition_number: float
        - warnings: List[str] of diagnostic messages
        - has_severe_multicollinearity: bool (any VIF > 10)
        - has_moderate_multicollinearity: bool (any VIF > 5)

    Note:
        VIF (Variance Inflation Factor) measures how much variance is inflated
        due to correlation with other factors. VIF = 1/(1 - R¬≤) where R¬≤ is
        from regressing factor i on all other factors.
    """
    from statsmodels.stats.outliers_influence import variance_inflation_factor

    vif_data = {}
    severe_factors = []
    moderate_factors = []

    # Calculate VIF for each factor
    for i, col in enumerate(X.columns):
        try:
            vif = variance_inflation_factor(X.values, i)
            vif_data[col] = float(vif) if np.isfinite(vif) else 999.9

            if vif > 10:
                severe_factors.append((col, vif))
            elif vif > 5:
                moderate_factors.append((col, vif))
        except Exception as e:
            # If VIF calculation fails (e.g., perfect collinearity)
            vif_data[col] = 999.9
            severe_factors.append((col, 999.9))

    # Calculate condition number
    try:
        condition_number = np.linalg.cond(X.values)
    except:
        condition_number = 999.9

    # Generate warnings
    warnings = []

    for factor, vif in severe_factors:
        warnings.append(
            f"{factor}: VIF={vif:.1f} (>10, severe multicollinearity - "
            f"consider removing or using ridge regression)"
        )

    for factor, vif in moderate_factors:
        warnings.append(
            f"{factor}: VIF={vif:.1f} (>5, moderate multicollinearity - "
            f"beta estimates may be unstable)"
        )

    if condition_number > 100:
        warnings.append(
            f"Condition number={condition_number:.1f} (>100, indicates "
            f"multicollinearity in factor matrix)"
        )

    return {
        'vif_values': vif_data,
        'condition_number': float(condition_number),
        'warnings': warnings,
        'has_severe_multicollinearity': len(severe_factors) > 0,
        'has_moderate_multicollinearity': len(moderate_factors) > 0,
        'max_vif': max(vif_data.values()) if vif_data else 0.0
    }
```

**Integration in calculate_factor_betas_hybrid**:

```python
# After line 370 (model fitting)
# Add multicollinearity diagnostics
multicollinearity_check = check_multicollinearity(X)

# Store in regression stats for this position
regression_stats[position_id]['multicollinearity'] = multicollinearity_check

# Log warnings
if multicollinearity_check['warnings']:
    for warning in multicollinearity_check['warnings']:
        logger.warning(f"Position {position_id}: {warning}")

# Optional: Flag positions with severe multicollinearity
if multicollinearity_check['has_severe_multicollinearity']:
    regression_stats[position_id]['quality_warning'] = 'SEVERE_MULTICOLLINEARITY'
```

**Impact**:
- ‚úÖ Detect unreliable beta estimates
- ‚úÖ Identify which factors are problematic
- ‚úÖ Guide model improvements (e.g., factor selection)
- ‚úÖ Align with MSCI Barra best practices

**Priority**: üü° Medium-High Value, Low Risk
**Effort**: 1.5 hours

---

### 2.2 Statistical Significance Thresholds

**Background**:

AQR research: "Just because a portfolio has a high beta coefficient doesn't mean it's statistically different than zero."

Non-significant betas (high p-values) are unreliable and shouldn't be trusted for portfolio decisions.

**Academic Standards**:
- p < 0.01: Highly significant (***)
- p < 0.05: Significant (**)
- p < 0.10: Marginally significant (*)
- p ‚â• 0.10: Not significant (ns)

**Proposed Solution**:

Add to `backend/app/calculations/factor_utils.py`:

```python
# Constants
SIGNIFICANCE_THRESHOLD_STRICT = 0.05  # 95% confidence
SIGNIFICANCE_THRESHOLD_RELAXED = 0.10  # 90% confidence

def classify_significance(p_value: float, strict: bool = False) -> Dict[str, Any]:
    """
    Classify statistical significance of a regression coefficient.

    Args:
        p_value: P-value from regression
        strict: If True, use 0.05 threshold; if False, use 0.10

    Returns:
        Dictionary with:
        - is_significant: bool
        - confidence_level: str ('***', '**', '*', 'ns')
        - interpretation: str (human-readable)
    """
    threshold = SIGNIFICANCE_THRESHOLD_STRICT if strict else SIGNIFICANCE_THRESHOLD_RELAXED

    if p_value < 0.01:
        level = '***'
        interpretation = 'highly significant (p < 0.01)'
    elif p_value < 0.05:
        level = '**'
        interpretation = 'significant (p < 0.05)'
    elif p_value < 0.10:
        level = '*'
        interpretation = 'marginally significant (p < 0.10)'
    else:
        level = 'ns'
        interpretation = 'not significant (p ‚â• 0.10)'

    return {
        'is_significant': p_value < threshold,
        'confidence_level': level,
        'interpretation': interpretation,
        'p_value': p_value,
        'threshold': threshold
    }
```

**Integration in calculate_factor_betas_hybrid**:

```python
# Around line 411, enhance regression stats
for factor_name in factor_columns:
    raw_beta = float(model.params.get(factor_name, 0.0))
    # ... existing beta capping logic ...

    p_value = float(model.pvalues.get(factor_name, 1.0))
    if not np.isfinite(p_value):
        p_value = 1.0

    std_err = float(model.bse.get(factor_name, 0.0))
    if not np.isfinite(std_err):
        std_err = 0.0

    # NEW: Classify significance
    significance = classify_significance(p_value, strict=False)

    position_betas[position_id][factor_name] = float(capped_beta)
    regression_stats[position_id][factor_name] = {
        'r_squared': model_r_squared,
        'p_value': p_value,
        'std_err': std_err,
        'observations': len(model_input),
        # NEW FIELDS
        'is_significant': significance['is_significant'],
        'confidence_level': significance['confidence_level'],
        'beta_t_stat': abs(capped_beta / std_err) if std_err > 0 else 0.0
    }

    # Warn on high non-significant betas
    if abs(capped_beta) > 1.0 and not significance['is_significant']:
        logger.warning(
            f"Position {position_id}, {factor_name}: High beta ({capped_beta:.2f}) "
            f"but {significance['interpretation']} (p={p_value:.3f}). "
            f"Consider this exposure unreliable for hedging decisions."
        )
```

**Impact**:
- ‚úÖ Identify unreliable factor exposures
- ‚úÖ Prevent over-hedging non-significant betas
- ‚úÖ Better risk management decisions
- ‚úÖ Align with AQR methodology

**Priority**: üü¢ High Value, Low Risk
**Effort**: 1 hour

---

### 2.3 R¬≤ Quality Classification

**Background**:

R¬≤ measures how much of position return variance is explained by the factor model.

Low R¬≤ means:
- Factor model doesn't explain position well
- Position has high idiosyncratic (non-factor) risk
- Beta estimates less reliable

**Academic Standards**:
- R¬≤ ‚â• 0.70: Excellent model fit (most variance explained)
- R¬≤ ‚â• 0.50: Good model fit
- R¬≤ ‚â• 0.30: Fair model fit
- R¬≤ < 0.30: Poor model fit (high idiosyncratic risk)

**Proposed Solution**:

Add to `backend/app/calculations/factor_utils.py`:

```python
# R¬≤ thresholds
R_SQUARED_THRESHOLDS = {
    'excellent': 0.70,
    'good': 0.50,
    'fair': 0.30,
    'poor': 0.10
}

def classify_r_squared(r_squared: float) -> Dict[str, Any]:
    """
    Classify R¬≤ (goodness of fit) for factor model.

    Args:
        r_squared: R¬≤ value from regression (0 to 1)

    Returns:
        Dictionary with:
        - quality: str ('excellent', 'good', 'fair', 'poor', 'very_poor')
        - interpretation: str
        - variance_explained_pct: float (R¬≤ as percentage)
        - idiosyncratic_risk_pct: float (100 - R¬≤)
    """
    if r_squared >= R_SQUARED_THRESHOLDS['excellent']:
        quality = 'excellent'
        interpretation = 'Factor model explains most variance'
    elif r_squared >= R_SQUARED_THRESHOLDS['good']:
        quality = 'good'
        interpretation = 'Factor model explains variance well'
    elif r_squared >= R_SQUARED_THRESHOLDS['fair']:
        quality = 'fair'
        interpretation = 'Moderate factor explanation, some idiosyncratic risk'
    elif r_squared >= R_SQUARED_THRESHOLDS['poor']:
        quality = 'poor'
        interpretation = 'High idiosyncratic risk, factor model limited'
    else:
        quality = 'very_poor'
        interpretation = 'Very high idiosyncratic risk, factor model inadequate'

    return {
        'quality': quality,
        'interpretation': interpretation,
        'variance_explained_pct': round(r_squared * 100, 1),
        'idiosyncratic_risk_pct': round((1 - r_squared) * 100, 1),
        'r_squared': r_squared
    }
```

**Integration**:

```python
# In calculate_factor_betas_hybrid, after fitting model (line 383)
model_r_squared = float(model.rsquared) if model.rsquared is not None else 0.0

# NEW: Classify R¬≤
r_squared_classification = classify_r_squared(model_r_squared)

# Store in position-level stats
regression_stats[position_id]['r_squared_quality'] = r_squared_classification['quality']
regression_stats[position_id]['r_squared_classification'] = r_squared_classification
regression_stats[position_id]['model_r_squared'] = model_r_squared

# Log quality warnings
if r_squared_classification['quality'] in ['poor', 'very_poor']:
    logger.info(
        f"Position {position_id}: {r_squared_classification['quality']} model fit "
        f"(R¬≤={model_r_squared:.3f}). {r_squared_classification['interpretation']}. "
        f"{r_squared_classification['idiosyncratic_risk_pct']}% idiosyncratic risk."
    )
```

**Impact**:
- ‚úÖ Identify positions with high idiosyncratic risk
- ‚úÖ Guide diversification decisions
- ‚úÖ Set appropriate confidence in beta estimates
- ‚úÖ Better risk attribution

**Priority**: üü¢ High Value, Low Risk
**Effort**: 45 minutes

---

### 2.4 Factor Correlation Analysis

**Background**:

Highly correlated factors can cause:
- Multicollinearity (inflated VIF)
- Redundant risk measurements
- Difficulty interpreting individual factor contributions

Understanding factor correlations helps:
- Validate factor independence assumptions
- Identify potential factor consolidation opportunities
- Explain unusual beta patterns

**Proposed Solution**:

Add to `backend/app/calculations/factor_utils.py`:

```python
def analyze_factor_correlations(
    factor_returns: pd.DataFrame,
    high_correlation_threshold: float = 0.7
) -> Dict[str, Any]:
    """
    Analyze correlations between factor returns.

    Args:
        factor_returns: DataFrame with factors as columns, dates as index
        high_correlation_threshold: Threshold for flagging high correlations

    Returns:
        Dictionary with:
        - correlation_matrix: Full correlation matrix
        - high_correlations: List of factor pairs with |corr| > threshold
        - avg_abs_correlation: Average absolute correlation
        - warnings: List of correlation warnings
    """
    # Calculate correlation matrix
    correlation_matrix = factor_returns.corr()

    # Find high correlations
    high_correlations = []
    warnings = []

    for i in range(len(correlation_matrix.columns)):
        for j in range(i + 1, len(correlation_matrix.columns)):
            factor1 = correlation_matrix.columns[i]
            factor2 = correlation_matrix.columns[j]
            corr = correlation_matrix.iloc[i, j]

            if abs(corr) > high_correlation_threshold:
                high_correlations.append({
                    'factor1': factor1,
                    'factor2': factor2,
                    'correlation': float(corr)
                })

                warnings.append(
                    f"{factor1} and {factor2} are highly correlated "
                    f"(r={corr:.3f}). This may cause multicollinearity."
                )

    # Calculate average absolute correlation
    # (excluding diagonal of 1.0)
    n = len(correlation_matrix)
    total_corr = 0.0
    count = 0

    for i in range(n):
        for j in range(i + 1, n):
            total_corr += abs(correlation_matrix.iloc[i, j])
            count += 1

    avg_abs_correlation = total_corr / count if count > 0 else 0.0

    return {
        'correlation_matrix': correlation_matrix.to_dict(),
        'high_correlations': high_correlations,
        'avg_abs_correlation': float(avg_abs_correlation),
        'warnings': warnings,
        'num_high_correlations': len(high_correlations)
    }
```

**Integration**:

```python
# In calculate_factor_betas_hybrid, after aligning data (line 318)
# Analyze factor correlations
factor_correlation_analysis = analyze_factor_correlations(
    factor_returns_aligned,
    high_correlation_threshold=0.7
)

logger.info(
    f"Factor correlation analysis: {factor_correlation_analysis['num_high_correlations']} "
    f"high correlations found, avg |r|={factor_correlation_analysis['avg_abs_correlation']:.3f}"
)

# Log warnings
for warning in factor_correlation_analysis['warnings']:
    logger.warning(f"Factor correlation: {warning}")

# Include in results
results['factor_correlations'] = factor_correlation_analysis
```

**Impact**:
- ‚úÖ Understand factor relationships
- ‚úÖ Validate 7-factor model assumptions
- ‚úÖ Identify potential model simplifications
- ‚úÖ Better interpret beta results

**Priority**: üü° Medium Value, Low Risk
**Effort**: 1 hour

---

## Part III: Implementation Plan

### Phase 1: Quick Wins (Week 1)
**Priority**: üü¢ High Value, Low Risk
**Total Effort**: ~3.5 hours

**Tasks**:
1. ‚úÖ Create `factor_utils.py` with centralized mappings (30 min)
2. ‚úÖ Add `FACTOR_NAME_MAPPING` constant (15 min)
3. ‚úÖ Add `get_default_storage_results()` (20 min)
4. ‚úÖ Add `get_default_data_quality()` (25 min)
5. ‚úÖ Add market value utilities (1 hour)
6. ‚úÖ Add R¬≤ classification (45 min)
7. ‚úÖ Add significance classification (30 min)

**Expected Outcomes**:
- ‚úÖ Better code organization
- ‚úÖ Consistent data structures
- ‚úÖ Enhanced diagnostics
- ‚úÖ No performance change

**Risk**: Very Low (pure additions, no breaking changes)

---

### Phase 2: Statistical Enhancements (Week 2)
**Priority**: üü° Medium-High Value, Low Risk
**Total Effort**: ~3.5 hours

**Tasks**:
1. ‚úÖ Add `check_multicollinearity()` function (1.5 hours)
2. ‚úÖ Integrate VIF checks in regression loop (30 min)
3. ‚úÖ Add significance flagging in regression stats (1 hour)
4. ‚úÖ Add factor correlation analysis (1 hour)
5. ‚úÖ Update logging with new diagnostics (30 min)

**Expected Outcomes**:
- ‚úÖ Detect multicollinearity issues
- ‚úÖ Flag unreliable betas
- ‚úÖ Better regression diagnostics
- ‚úÖ Improved factor model validation

**Risk**: Low (additive enhancements, no calculation changes)

---

### Phase 3: Portfolio Context Refactoring (Week 3-4)
**Priority**: üî¥ Very High Value, Medium Risk
**Total Effort**: ~8-10 hours

**Prerequisites**:
- ‚úÖ Phase 1 complete
- ‚úÖ Comprehensive unit tests written
- ‚úÖ Integration tests passing

**Tasks**:

**3.1 Core Infrastructure** (2 hours):
1. ‚úÖ Implement `PortfolioContext` dataclass
2. ‚úÖ Implement `load_portfolio_context()` function
3. ‚úÖ Add context caching properties
4. ‚úÖ Write unit tests for context loading

**3.2 Refactor calculate_position_returns** (1.5 hours):
1. ‚úÖ Add optional `context` parameter
2. ‚úÖ Use `context.public_positions` instead of DB query
3. ‚úÖ Update skip logic with context position counts
4. ‚úÖ Test backward compatibility (context=None)

**3.3 Refactor calculate_factor_betas_hybrid** (2 hours):
1. ‚úÖ Add optional `context` parameter
2. ‚úÖ Load context at function start if not provided
3. ‚úÖ Pass context to `calculate_position_returns()`
4. ‚úÖ Pass context to `_aggregate_portfolio_betas()`
5. ‚úÖ Enhanced skip payload with context data
6. ‚úÖ Test both with and without context

**3.4 Refactor _aggregate_portfolio_betas** (1 hour):
1. ‚úÖ Add required `context` parameter
2. ‚úÖ Use `context.equity_balance` instead of DB query
3. ‚úÖ Use `context.active_positions` instead of DB query
4. ‚úÖ Update all call sites

**3.5 Refactor storage functions** (2 hours):
1. ‚úÖ Update `store_position_factor_exposures()` to accept context
2. ‚úÖ Use `context.factor_name_to_id` instead of querying
3. ‚úÖ Update `aggregate_portfolio_factor_exposures()` to accept context
4. ‚úÖ Use shared market value utilities
5. ‚úÖ Test storage with mock context

**3.6 Integration Testing** (1.5 hours):
1. ‚úÖ Test full calculation flow with context
2. ‚úÖ Verify DB query count reduction (measure!)
3. ‚úÖ Ensure identical outputs to old version
4. ‚úÖ Performance benchmarking

**Expected Outcomes**:
- ‚úÖ **62% reduction in DB queries** (7 ‚Üí 3)
- ‚úÖ Faster calculation execution
- ‚úÖ Better batch processing performance
- ‚úÖ Easier to test and mock

**Risk**: Medium
- Complex refactoring with multiple function changes
- Must maintain backward compatibility
- Need comprehensive testing

**Rollback Plan**:
- Keep context parameter optional (`context=None`)
- Old behavior works without context
- Can gradually migrate call sites

---

## Part IV: Success Metrics

### Performance Metrics

**Before Optimization**:
- Database queries per calculation: ~7-8
- Average calculation time: TBD (measure baseline)
- Batch processing time (3 portfolios): TBD

**After Phase 1 & 2**:
- Database queries: ~7-8 (no change)
- Calculation time: Similar
- New: Comprehensive diagnostics added

**After Phase 3**:
- Database queries per calculation: ~3 (**62% reduction**)
- Average calculation time: TBD (expect 20-30% improvement)
- Batch processing time: TBD (expect 25-35% improvement)

### Quality Metrics

**New Diagnostic Outputs**:
1. ‚úÖ VIF values for each factor
2. ‚úÖ Condition number for factor matrix
3. ‚úÖ Statistical significance classifications
4. ‚úÖ R¬≤ quality classifications
5. ‚úÖ Factor correlation matrix
6. ‚úÖ Enhanced skip reason metadata
7. ‚úÖ Position count summaries

**Detection Capabilities**:
- Multicollinearity warnings
- Non-significant beta warnings
- Poor model fit warnings
- High factor correlation warnings

### Code Quality Metrics

**Before**:
- Code duplication: Factor mapping in 2 places, market value in 2+ places
- Database queries: Unoptimized
- Test coverage: TBD

**After**:
- Code duplication: Eliminated (centralized utilities)
- Database queries: Optimized
- Test coverage: Target >80% for new code
- Maintainability: Single source of truth for all shared logic

---

## Part V: Validation & Testing

### Unit Tests Required

**Phase 1 Tests** (`test_factor_utils.py`):
```python
def test_normalize_factor_name()
def test_get_position_market_value_long()
def test_get_position_market_value_options()
def test_get_position_signed_exposure_short()
def test_get_position_magnitude_exposure()
def test_get_default_storage_results()
def test_classify_r_squared()
def test_classify_significance()
```

**Phase 2 Tests**:
```python
def test_check_multicollinearity_no_issues()
def test_check_multicollinearity_severe()
def test_analyze_factor_correlations()
```

**Phase 3 Tests**:
```python
def test_load_portfolio_context()
def test_portfolio_context_properties()
def test_calculate_position_returns_with_context()
def test_calculate_factor_betas_with_context()
def test_backward_compatibility_no_context()
def test_database_query_count()  # Most important!
```

### Integration Tests

**Critical Validation**:
1. ‚úÖ Same outputs with and without context (numerical equality)
2. ‚úÖ Database query count verification
3. ‚úÖ Full calculation pipeline test (end-to-end)
4. ‚úÖ Performance benchmarking

**Test Data**:
- Use existing demo portfolios (3 portfolios, 63 positions)
- Test skip conditions (no public positions, insufficient data)
- Test various position types (long, short, options)

---

## Part VI: Risk Assessment & Mitigation

### Technical Risks

**Risk 1: Refactoring Introduces Bugs** ‚ö†Ô∏è
- **Probability**: Medium
- **Impact**: High (calculation errors)
- **Mitigation**:
  - Comprehensive unit tests before refactoring
  - Numerical equality tests (old vs new outputs)
  - Gradual rollout with context parameter optional
  - Code review by senior engineer

**Risk 2: Performance Regression** ‚ö†Ô∏è
- **Probability**: Low
- **Impact**: Medium
- **Mitigation**:
  - Benchmark before/after
  - Profile code to identify bottlenecks
  - Monitor production metrics
  - Rollback plan ready

**Risk 3: Breaking Changes to API** ‚ö†Ô∏è
- **Probability**: Low (if done carefully)
- **Impact**: High
- **Mitigation**:
  - Make all new parameters optional
  - Maintain backward compatibility
  - Version API if needed
  - Update API documentation

**Risk 4: Incomplete Test Coverage** ‚ö†Ô∏è
- **Probability**: Medium
- **Impact**: High
- **Mitigation**:
  - Set target >80% coverage for new code
  - Test all edge cases
  - Include regression tests
  - Manual QA on demo portfolios

### Business Risks

**Risk 5: Development Time Overruns** ‚ö†Ô∏è
- **Probability**: Medium
- **Impact**: Medium
- **Mitigation**:
  - Phased approach allows partial delivery
  - Phase 1 & 2 deliver value without Phase 3
  - Clear scope definition
  - Regular progress checkpoints

**Risk 6: User-Facing Impact** ‚ö†Ô∏è
- **Probability**: Low
- **Impact**: High
- **Mitigation**:
  - No user-facing changes (backend only)
  - Enhanced diagnostics improve user experience
  - Better error messages and skip reasons

---

## Part VII: Code Examples

### Example 1: Using Portfolio Context

**Before** (duplicate queries):
```python
async def calculate_factor_betas_hybrid(db, portfolio_id, calculation_date):
    # Query 1: Get positions
    positions = await db.execute(select(Position).where(...))

    # ... later in function ...

    # Query 2: Get portfolio (duplicate effort)
    portfolio = await db.execute(select(Portfolio).where(...))

    # ... later in function ...

    # Query 3: Get positions again (another duplicate!)
    positions_again = await db.execute(select(Position).where(...))
```

**After** (single context load):
```python
async def calculate_factor_betas_hybrid(
    db,
    portfolio_id,
    calculation_date,
    context=None
):
    # Load context once (3 queries total)
    if context is None:
        context = await load_portfolio_context(db, portfolio_id, calculation_date)

    # Use cached data throughout
    positions = context.public_positions
    equity = context.equity_balance
    factor_ids = context.factor_name_to_id

    # No more duplicate queries!
```

### Example 2: Enhanced Diagnostics

**Before** (minimal output):
```python
regression_stats[position_id][factor_name] = {
    'r_squared': 0.42,
    'p_value': 0.08,
    'std_err': 0.15
}
```

**After** (rich diagnostics):
```python
regression_stats[position_id][factor_name] = {
    'r_squared': 0.42,
    'p_value': 0.08,
    'std_err': 0.15,
    # NEW: Significance analysis
    'is_significant': True,
    'confidence_level': '*',  # marginally significant
    'beta_t_stat': 2.13,
    # NEW: From R¬≤ classification
    'r_squared_quality': 'fair',
    'variance_explained_pct': 42.0,
    'idiosyncratic_risk_pct': 58.0
}

# NEW: Multicollinearity diagnostics
regression_stats[position_id]['multicollinearity'] = {
    'vif_values': {'Market': 1.2, 'Value': 2.8, ...},
    'condition_number': 45.3,
    'has_severe_multicollinearity': False
}
```

---

## Part VIII: Documentation Updates Required

### Code Documentation
1. ‚úÖ Update `factors.py` docstrings with context parameter
2. ‚úÖ Add comprehensive docstrings to `factor_utils.py`
3. ‚úÖ Update `AI_AGENT_REFERENCE.md` with new patterns
4. ‚úÖ Add examples to `API_REFERENCE_V1.4.6.md`

### User Documentation
1. ‚úÖ Update portfolio report explanations (significance stars)
2. ‚úÖ Add glossary entries (VIF, R¬≤, p-value)
3. ‚úÖ Document quality warning interpretations

### Developer Documentation
1. ‚úÖ Migration guide for using PortfolioContext
2. ‚úÖ Testing guide for factor calculations
3. ‚úÖ Performance optimization best practices

---

## Part IX: Rollout Plan

### Week 1: Phase 1 Implementation
- **Mon-Tue**: Create `factor_utils.py`, add mappings and utilities
- **Wed-Thu**: Add classification functions and defaults
- **Fri**: Unit tests, code review

### Week 2: Phase 2 Implementation
- **Mon-Tue**: Add multicollinearity and correlation analysis
- **Wed-Thu**: Integrate into `factors.py`
- **Fri**: Testing, validation, documentation

### Week 3-4: Phase 3 Implementation
- **Week 3 Mon-Wed**: Implement PortfolioContext
- **Week 3 Thu-Fri**: Refactor calculate_position_returns
- **Week 4 Mon-Tue**: Refactor main calculation function
- **Week 4 Wed**: Refactor storage functions
- **Week 4 Thu-Fri**: Integration testing, benchmarking, validation

### Week 5: Deployment & Monitoring
- **Mon**: Final code review
- **Tue**: Deploy to staging
- **Wed-Thu**: QA testing, performance validation
- **Fri**: Production deployment, monitoring

---

## Part X: Future Enhancements (Post-Plan)

### Not Included in This Plan (Future Work)

1. **Options Delta Adjustment** ‚è∏Ô∏è
   - Acknowledged technical debt
   - Requires integration with Greeks calculations
   - Medium effort, high impact for options-heavy portfolios

2. **Risk-Free Rate Adjustment** ‚è∏Ô∏è
   - Minor theoretical gap
   - Low impact in current rate environment
   - Easy to add once risk-free rate source established

3. **Ridge Regression for Multicollinearity** ‚è∏Ô∏è
   - Alternative to OLS when VIF > 10
   - Requires parameter tuning
   - Consider if severe multicollinearity detected

4. **Exponentially Weighted Regression** ‚è∏Ô∏è
   - Weight recent data more heavily
   - More responsive to regime changes
   - Adds complexity, need to tune half-life

5. **Factor Model Validation** ‚è∏Ô∏è
   - Compare ETF proxies vs fundamental factors
   - Backtest optimal window length
   - Validate factor selection

---

## Conclusion

This enhancement plan will upgrade the factor analysis engine from **A- (9.0/10) to A+ (9.5/10)** by:

1. **Improving Performance**: 62% reduction in database queries
2. **Enhancing Quality**: Comprehensive statistical diagnostics
3. **Increasing Maintainability**: Centralized utilities, DRY principle
4. **Better Observability**: Rich diagnostic metadata

The phased approach allows:
- ‚úÖ Early value delivery (Phase 1 & 2)
- ‚úÖ Risk mitigation through incremental changes
- ‚úÖ Flexibility to pause after any phase
- ‚úÖ Backward compatibility maintained

**Recommendation**: Proceed with implementation following the 3-phase plan. The code efficiency improvements alone (Phase 3) will provide significant production benefits, while the statistical enhancements (Phases 1-2) align the implementation with academic best practices and industry standards (MSCI Barra, AQR, Bloomberg).

---

**Document End**
