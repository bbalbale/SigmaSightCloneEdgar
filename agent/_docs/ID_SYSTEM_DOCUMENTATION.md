# ID System Documentation

## Overview
This document describes the ID management system implemented in Phase 10 of the SigmaSight backend/frontend integration. The system provides backend-first ID generation with clean API separation and multi-LLM provider support.

## Architecture

### ID Types and Formats

1. **Message IDs**: UUID v4 format
   - Generated by backend exclusively
   - Example: `35efa213-5b70-4fc2-88a1-86bdb4d2f112`

2. **Conversation IDs**: UUID v4 format
   - Generated by backend when creating conversations
   - Example: `851c9af1-9401-4881-8235-32614bdbf4a2`

3. **Tool Call IDs**: Provider-specific format
   - OpenAI: `call_{24_hex_chars}`
   - Example: `call_YU5Ckc2nY1AlaDN64xpapg0P`

4. **Run IDs**: Session-specific identifiers
   - Format: `run_{uuid_hex[:12]}`
   - Used for SSE streaming coordination

## Backend Components

### LLM Provider Base (`backend/app/utils/llm_provider_base.py`)
Abstract base class defining the provider interface:
- `generate_universal_message_id()`: Creates backend message IDs
- `generate_provider_tool_call_id()`: Creates provider-specific tool call IDs
- `validate_tool_call_id()`: Validates provider ID formats

### OpenAI Provider (`backend/app/utils/llm_providers/openai_provider.py`)
OpenAI-specific implementation:
- Generates `call_{24_hex}` format tool call IDs
- Handles message formatting for OpenAI API
- Provides backward compatibility for malformed tool calls

### SSE Event: message_created
Emitted immediately after creating messages in the database:
```json
{
  "user_message_id": "uuid-here",
  "assistant_message_id": "uuid-here",
  "conversation_id": "uuid-here",
  "run_id": "run-id-here"
}
```

## Frontend Integration

### Chat Store Changes
- Removed frontend ID generation
- `addMessage()` requires backend ID parameter
- `getMessage()` method for ID lookups
- `handleMessageCreated()` processes backend IDs

### Stream Store Changes
- Added `currentAssistantMessageId` field
- `setAssistantMessageId()` for backend coordination
- Maintains `run_id` for buffer management

### Chat Interface Flow
1. User sends message
2. Frontend creates temporary message object (no ID)
3. Backend creates messages with IDs
4. Backend emits `message_created` event
5. Frontend adds messages with backend IDs
6. Streaming continues with established IDs

## API Endpoints

### POST `/api/v1/chat/conversations`
Creates a new conversation with backend-generated ID.

**Response:**
```json
{
  "id": "851c9af1-9401-4881-8235-32614bdbf4a2",
  "mode": "green",
  "created_at": "2025-09-02T12:00:00Z"
}
```

### POST `/api/v1/chat/send`
Sends a message and streams response via SSE.

**SSE Events:**
- `message_created`: Provides all backend-generated IDs
- `token`: Streaming content tokens
- `tool_call`: Tool execution events
- `done`: Completion event

## Troubleshooting Guide

### Common Issues

1. **Missing message_created event**
   - Check SSE connection is established
   - Verify authentication (JWT token)
   - Ensure proper Accept header: `text/event-stream`

2. **Invalid UUID format errors**
   - All IDs must be valid UUID v4
   - Check backend is generating IDs (not frontend)
   - Verify message_created event is processed

3. **Tool call ID errors (OpenAI 400)**
   - Must be format: `call_{24_hex_chars}`
   - Check OpenAI provider is being used
   - Verify tool calls have IDs before sending to OpenAI

4. **Frontend not receiving IDs**
   - Check onMessageCreated callback is defined
   - Verify SSE event parsing for message_created
   - Ensure chatStore.handleMessageCreated is called

### Validation Methods

Test script available at `backend/test_phase_10_5.py`:
```bash
cd backend
uv run python test_phase_10_5.py
```

Tests verify:
- Backend provides valid UUIDs
- SSE events include message_created
- Tool calls have proper format
- No ID collisions in concurrent conversations

## Migration Notes

### From Frontend-Generated IDs
Old format: `msg_${timestamp}_${random}`
New format: UUID from backend

Migration handled automatically:
- Backend always provides IDs
- Frontend falls back gracefully if backend unavailable
- No database migration needed (backend already used UUIDs)

### Backward Compatibility
- Existing conversations continue working
- Malformed tool calls are fixed automatically
- OpenAI provider handles legacy formats

## Security Considerations

1. **ID Generation**: Only backend generates IDs (security boundary)
2. **ID Validation**: All IDs validated before database operations
3. **No ID Exposure**: Internal IDs not exposed in API responses
4. **Provider Isolation**: Provider-specific IDs isolated from core system

## Future Enhancements

### Multi-LLM Support
The provider abstraction enables easy addition of new LLM providers:
- Anthropic: Would use different tool call ID format
- Google: Would use different message structure
- Custom: Can implement provider-specific requirements

### Performance Optimizations
- ID caching for frequently accessed messages
- Batch ID generation for multiple messages
- Optimistic UI updates with ID reservation

## References
- Design Document: `agent/_docs/requirements/DESIGN_DOC_ID_REFACTOR_V1.0.md`
- Implementation Plan: `agent/TODO.md` (Phase 10)
- Test Results: `backend/phase_10_5_results.json`